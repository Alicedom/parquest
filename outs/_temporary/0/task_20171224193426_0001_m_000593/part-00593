(cache</dd>,19)
(name="fs.protected.directories">fs.protected.directories</a></td><td></td><td>A,1)
(currentId_</pre>,1)
(org.apache.hadoop.metrics2.lib">DefaultMetricsSystem</a>&gt;</dd>,3)
(Class<br>org.apache.hadoop.fs.FsShellPermissions.Chown</h2>,2)
(href="./org/apache/hadoop/ipc/protobuf/IpcConnectionContextProtos.IpcConnectionContextProto.Builder.html#build()">build()</a></span>,2)
(name="wrappedReadForCompressedData(java.io.InputStream,,3)
(href="../../api/index.html">Hadoop,1)
(<h4>getSubCluster</h4>,7)
(href="./org/apache/hadoop/hdfs/util/LightWeightHashSet.html#getCapacity()">getCapacity()</a></span>,1)
(href="../../../../../org/apache/hadoop/hdfs/protocolPB/PBHelper.html#convert(org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.FinalizeCommandProto)">convert</a></strong>(org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos.FinalizeCommandProto&nbsp;finalizeCmd)</code>&nbsp;</td>,2)
(java.lang">String</a>&nbsp;log4jPath),1)
(<pre>public&nbsp;JobClient(<a,5)
(org.apache.hadoop.net">InnerNodeImpl.Factory</a></dt>,4)
(href="../../../../org/apache/hadoop/mapred/BackupStore.html#getOutputStream(int)">getOutputStream</a></strong>(int&nbsp;length)</code>,1)
(V]|��,1)
(<tt>Container_</tt><b>e{epoch}</b><tt>_{clusterTimestamp}_{appId}_{attemptId}_{containerId}</tt>,,1)
(href="../../../../../../org/apache/hadoop/yarn/api/records/class-use/ContainerSubState.html#org.apache.hadoop.yarn.api.records">ContainerSubState</a>,2)
(<pre>public&nbsp;MultiSchemeAuthenticationHandler(<a,1)
(name="org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairSchedulerConfiguration.DEFAULT_RM_SCHEDULER_INCREMENT_ALLOCATION_MB">,1)
(<pre>public&nbsp;boolean&nbsp;hasSomeData(),2)
(DirectBufferPool,1)
(href="class-use/Metric.Type.html">Use</a></li>,4)
(href="../../../../org/apache/hadoop/util/DiskChecker.DiskOutOfSpaceException.html#DiskChecker.DiskOutOfSpaceException(java.lang.String)">DiskChecker.DiskOutOfSpaceException</a></strong>(<a,2)
(name="hasAccess(java.lang.String,,1)
