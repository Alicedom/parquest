(org.apache.hadoop.ipc.proto">GenericRefreshProtocolProtos.GenericRefreshResponseProto.Builder</a>&nbsp;newBuilderForType(com.google.protobuf.GeneratedMessage.BuilderParent&nbsp;parent)</pre>,2)
(limits.</p>,2)
(Class<br>org.apache.hadoop.hdfs.server.federation.router.ConnectionManager</h2>,2)
(rebuilt.</li>,1)
(httpcore,1)
(<i>time-to-live,1)
(<pre>public&nbsp;void&nbsp;undoModify(<a,2)
(href="./org/apache/hadoop/fs/FileChecksum.html#getLength()">getLength()</a></span>,3)
(href="../../../../org/apache/hadoop/util/Shell.html#USER_NAME_COMMAND">USER_NAME_COMMAND</a>,,2)
(href="../../../../../../../../../org/apache/hadoop/yarn/server/nodemanager/containermanager/logaggregation/AppLogAggregator.html",7)
(href="../../../../../../org/apache/hadoop/hdfs/server/namenode/FsImageProto.SnapshotSection.Builder.html#build()">build</a></strong>()</code>&nbsp;</td>,2)
(Hamlet.DT">T</a>&gt;&gt;&nbsp;object()</pre>,1)
(UNINITIALIZED_MEMORY_VALUE,6)
(href="../../../../../../../org/apache/hadoop/hdfs/qjournal/protocol/QJournalProtocolProtos.GetJournalStateResponseProto.html#parseFrom(java.io.InputStream,%20com.google.protobuf.ExtensionRegistryLite)">parseFrom</a></strong>(<a,2)
(org.apache.hadoop.mapreduce.jobhistory">JobSubmitted</a></dd>,1)
(href="../../../../../../constant-values.html#org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFilter.FILTER_CLASS">Constant,2)
(href="./org/apache/hadoop/security/authentication/server/AuthenticationToken.html#setExpires(long)">setExpires(long)</a></span>,1)
(org.apache.hadoop.hdfs.qjournal.protocol"><i>QJournalProtocolProtos.DoPreUpgradeResponseProtoOrBuilder</i></a></li>,1)
(href="./org/apache/hadoop/yarn/client/RMFailoverProxyProvider.html#init(org.apache.hadoop.conf.Configuration,%20org.apache.hadoop.yarn.client.RMProxy,%20java.lang.Class)">init(Configuration,,1)
(LocalizerTokenSelector",1)
(org.apache.hadoop.ipc.protobuf">RpcHeaderProtos.RPCTraceInfoProtoOrBuilder</a>,2)
(href="../../../../../../../org/apache/hadoop/mapreduce/v2/app/rm/RMContainerAllocator.html#RAMPDOWN_DIAGNOSTIC">RAMPDOWN_DIAGNOSTIC</a></strong></code>&nbsp;</td>,1)
(org.apache.hadoop.yarn.api.records">LogAggregationStatus</a>,8)
(href="../../../../../../org/apache/hadoop/mapreduce/MRJobConfig.html#COUNTER_GROUP_NAME_MAX_DEFAULT">COUNTER_GROUP_NAME_MAX_DEFAULT</a>,,2)
(<p>SaslRpcServer.SASL_PROPS,1)
(Hamlet.SUB">T</a>&gt;&nbsp;bdo(<a,1)
(<p>Made,3)
(class="strong">Returns:</span></dt><dd>CompressionInputStream,3)
(Parser",4)
(href="./org/apache/hadoop/yarn/webapp/hamlet/HamletSpec.FORM.html#$accept(java.lang.String)">$accept(String)</a></span>,1)
((java.io.tmpdir),1)
(href="./org/apache/hadoop/yarn/api/records/impl/pb/QueueStatisticsPBImpl.html#setPendingMemoryMB(long)">setPendingMemoryMB(long)</a></span>,1)
(<h4>TaskAttemptFinished</h4>,2)
(href="../../../../../../../org/apache/hadoop/yarn/server/resourcemanager/reservation/ReservationAllocation.html#containsGangs()">containsGangs</a></strong>()</code>,1)
(<pre>public&nbsp;boolean&nbsp;hasNumInodes()</pre>,4)
(href="../../../../../org/apache/hadoop/io/compress/SplittableCompressionCodec.html#createInputStream(java.io.InputStream,%20org.apache.hadoop.io.compress.Decompressor,%20long,%20long,%20org.apache.hadoop.io.compress.SplittableCompressionCodec.READ_MODE)">createInputStream</a></strong>(<a,3)
(ï¿½f,1)
